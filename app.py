# ğŸ“š í†µí•©ëœ Streamlit ì›¹ì•±: ISBN -> MARC ë³€í™˜ê¸° (KDC, NLK, ì•Œë¼ë”˜ í†µí•©)

import streamlit as st
import os
import requests
import pandas as pd
import google.generativeai as genai
import xml.etree.ElementTree as ET
import re
import io

# ğŸ” API í‚¤ë“¤
TTB_KEY = "ttbdawn63091003001"
NLK_KEY = "45b1715858c57fa38cdefdf80fefdca3502e93f2e03576bde074048b412da3db"

# âœ… Gemini API
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=API_KEY)
except Exception as e:
    st.error(f"Gemini API ì„¤ì • ì˜¤ë¥˜: {e}")

# ğŸ¯ Gemini ê¸°ë°˜ KDC ì¶”ì²œ
@st.cache_data(show_spinner=False)
def recommend_kdc(title, author):
    prompt = f"""ë„ì„œ ì œëª©: {title}
ì €ì: {author}
ì´ ì±…ì— ê°€ì¥ ì ì ˆí•œ í•œêµ­ì‹­ì§„ë¶„ë¥˜(KDC) ë²ˆí˜¸ 1ê°œë¥¼ ì¶”ì²œí•´ì¤˜.
ì •í™•í•œ ìˆ«ìë§Œ ì•„ë˜ í˜•ì‹ì²˜ëŸ¼ ê°„ê²°í•˜ê²Œ ë§í•´ì¤˜:
KDC: 813.7"""
    try:
        model = genai.GenerativeModel("gemini-1.5-pro-latest")
        response = model.generate_content(prompt)
        for line in response.text.strip().splitlines():
            if "KDC:" in line:
                return line.replace("KDC:", "").strip()
    except:
        return "000"
    return "000"

# ğŸ§  ì–¸ì–´ì½”ë“œ & ì–¸ì–´íŒë³„
ISDS_LANGUAGE_CODES = {'kor': 'í•œêµ­ì–´', 'eng': 'ì˜ì–´', 'jpn': 'ì¼ë³¸ì–´', 'chi': 'ì¤‘êµ­ì–´', 'rus': 'ëŸ¬ì‹œì•„ì–´', 'ara': 'ì•„ëì–´', 'fre': 'í”„ë‘ìŠ¤ì–´', 'ger': 'ë…ì¼ì–´', 'ita': 'ì´íƒˆë¦¬ì•„ì–´', 'spa': 'ìŠ¤í˜ì¸ì–´', 'und': 'ì•Œ ìˆ˜ ì—†ìŒ'}

def detect_language(text):
    text = re.sub(r'[\s\W_]+', '', text)
    if not text: return 'und'
    ch = text[0]
    if '\uac00' <= ch <= '\ud7a3': return 'kor'
    elif '\u3040' <= ch <= '\u30ff': return 'jpn'
    elif '\u4e00' <= ch <= '\u9fff': return 'chi'
    elif '\u0400' <= ch <= '\u04FF': return 'rus'
    elif 'a' <= ch.lower() <= 'z': return 'eng'
    else: return 'und'

def generate_546_from_041_kormarc(marc_041):
    a_codes, h_code = [], None
    for part in marc_041.split():
        if part.startswith("$a"): a_codes.append(part[2:])
        elif part.startswith("$h"): h_code = part[2:]

    if len(a_codes) == 1:
        a_lang = ISDS_LANGUAGE_CODES.get(a_codes[0], "ì•Œ ìˆ˜ ì—†ìŒ")
        if h_code:
            h_lang = ISDS_LANGUAGE_CODES.get(h_code, "ì•Œ ìˆ˜ ì—†ìŒ")
            return f"{a_lang}ë¡œ ì”€, ì›ì €ëŠ” {h_lang}ì„"
        else:
            return f"{a_lang}ë¡œ ì”€"
    elif len(a_codes) > 1:
        langs = [ISDS_LANGUAGE_CODES.get(code, "ì•Œ ìˆ˜ ì—†ìŒ") for code in a_codes]
        return f"{'ã€'.join(langs)} ë³‘ê¸°"
    else:
        return "ì–¸ì–´ ì •ë³´ ì—†ìŒ"

def get_kormarc_041_tag(isbn):
    params = {"ttbkey": TTB_KEY, "itemIdType": "ISBN13", "ItemId": isbn, "output": "xml", "Version": "20131101"}
    response = requests.get("https://www.aladin.co.kr/ttb/api/ItemLookUp.aspx", params=params)
    try:
        root = ET.fromstring(response.content)
        ns = {"ns": "http://www.aladin.co.kr/ttb/apiguide.aspx"}
        item = root.find("ns:item", namespaces=ns)
        title = item.findtext("ns:title", default="", namespaces=ns)
        original = item.find("ns:subInfo", namespaces=ns).findtext("ns:originalTitle", default="", namespaces=ns)
        lang_a = detect_language(title)
        lang_h = detect_language(original)
        marc_041 = f"041 $a{lang_a} {'$h'+lang_h if original else ''}".strip()
        marc_546 = generate_546_from_041_kormarc(marc_041)
        return marc_041, marc_546
    except:
        return "041 ì˜¤ë¥˜", ""

# ğŸ“š NLK ê¸°ë°˜ 245 + 700 ìƒì„±
from bs4 import BeautifulSoup

def fetch_from_nlk(isbn, nlk_key):
    url = f"https://www.nl.go.kr/seoji/SearchApi.do?cert_key={nlk_key}&result_style=xml&page_no=1&page_size=10&isbn={isbn}"
    try:
        res = requests.get(url, timeout=10)
        root = ET.fromstring(res.text)
        doc = root.find('.//docs/e')
        return doc.findtext('TITLE'), doc.findtext('AUTHOR')
    except:
        return "ì œëª©ì—†ìŒ", "ì§€ì€ì´ ë¯¸ìƒ"

def reverse_name_order(name):
    parts = name.strip().split()
    return f"{parts[-1]}, {' '.join(parts[:-1])}" if len(parts) >= 2 else name

def split_title(full):
    for sep in [":", "-", "ï¼š", "â€“"]:
        if sep in full:
            return full.split(sep, 1)[0].strip(), full.split(sep, 1)[1].strip()
    return full.strip(), ""

def generate_245(title_str, author_str):
    title, subtitle = split_title(title_str)
    writer, translator = "", ""
    for entry in author_str.split(";"):
        if "ì§€ì€ì´" in entry: writer = entry.split(":", 1)[1].strip()
        if "ì˜®ê¸´ì´" in entry: translator = entry.split(":", 1)[1].strip()
    parts = []
    if writer:
        w_list = [f"$d{name}" for name in writer.split(",") if name.strip()]
        if w_list: w_list[-1] += " ì§€ìŒ"
        parts.append(", ".join(w_list))
    if translator:
        t_list = [name.strip() for name in translator.split(",") if name.strip()]
        if t_list: parts.append(";$e" + ", $e".join(t_list) + " ì˜®ê¹€")
    line = f"=245  00$a{title}"
    if subtitle: line += f" :$b{subtitle}"
    if parts: line += f" /{' '.join(parts)}"
    return line

def generate_700(author_str):
    lines = []
    for entry in author_str.split(";"):
        if "ì§€ì€ì´" in entry or "ì˜®ê¸´ì´" in entry:
            try: raw = entry.split(":", 1)[1]
            except: continue
            for name in raw.split(","):
                if ' ' in name:
                    lines.append(f"=700  1\\$a{reverse_name_order(name)}")
                else:
                    lines.append(f"=700  1\\$a{name.strip()}")
    return lines

def generate_nlk_marc_fields(isbn):
    title, author = fetch_from_nlk(isbn, NLK_KEY)
    if not title or not author: return None, None, []
    return title, author, [generate_245(title, author)] + generate_700(author)

# ğŸ“š ì•Œë¼ë”˜ ê¸°ë°˜ í•„ë“œ ìƒì„±
@st.cache_data(show_spinner=False)
def fetch_book_data_from_aladin(isbn, reg_mark="", reg_no="", copy_symbol=""):
    url = f"https://www.aladin.co.kr/ttb/api/ItemLookUp.aspx?ttbkey={TTB_KEY}&itemIdType=ISBN&ItemId={isbn}&output=js&Version=20131101"
    response = requests.get(url, verify=False)
    data = response.json().get("item", [{}])[0]
    title, author = data.get("title", "ì œëª©ì—†ìŒ"), data.get("author", "ì €ìë¯¸ìƒ")
    publisher, pubdate = data.get("publisher", "ì¶œíŒì‚¬ë¯¸ìƒ"), data.get("pubDate", "2025")[:4]
    price = data.get("priceStandard")
    series_title = data.get("seriesInfo", {}).get("seriesName", "").strip()
    kdc = recommend_kdc(title, author)
    marc = f"=001  {isbn}\n=245  10$a{title} /$c{author}\n=260  \\$aì„œìš¸ :$b{publisher},$c{pubdate}.\n=020  \\$a{isbn}" + (f":$c\{price}" if price else "")
    if kdc and kdc != "000": marc += f"\n=056  \\$a{kdc}$26"
    if series_title:
        marc += f"\n=490  10$a{series_title} ;$v\n=830  \\0$a{series_title} ;$v"
    if price: marc += f"\n=950  0\\$b\{price}"
    if reg_mark or reg_no or copy_symbol:
        marc += f"\n=049  0\\$I{reg_mark}{reg_no}" + (f"$f{copy_symbol}" if copy_symbol else "")
    return marc

# ğŸ›ï¸ UI ì˜ì—­
st.title("ğŸ“š ISBN to MARC ë³€í™˜ê¸° + KDC + 041/546 + NLK")

isbn_list = []
single_isbn = st.text_input("ğŸ”¹ ë‹¨ì¼ ISBN ì…ë ¥", placeholder="ì˜ˆ: 9788936434267")

if single_isbn.strip():
    isbn_list = [[single_isbn.strip(), "", "", ""]]

uploaded_file = st.file_uploader("ğŸ“ CSV ì—…ë¡œë“œ (ISBN, ë“±ë¡ê¸°í˜¸, ë“±ë¡ë²ˆí˜¸, ë³„ì¹˜ê¸°í˜¸)", type="csv")
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    if {'ISBN', 'ë“±ë¡ê¸°í˜¸', 'ë“±ë¡ë²ˆí˜¸', 'ë³„ì¹˜ê¸°í˜¸'}.issubset(df.columns):
        isbn_list = df[['ISBN', 'ë“±ë¡ê¸°í˜¸', 'ë“±ë¡ë²ˆí˜¸', 'ë³„ì¹˜ê¸°í˜¸']].dropna(subset=['ISBN']).values.tolist()
    else:
        st.error("âŒ í•„ìš”í•œ ì—´ì´ ì—†ìŠµë‹ˆë‹¤: ISBN, ë“±ë¡ê¸°í˜¸, ë“±ë¡ë²ˆí˜¸, ë³„ì¹˜ê¸°í˜¸")

if isbn_list:
    st.subheader("ğŸ“„ MARC ì¶œë ¥")
    marc_results = []
    for row in isbn_list:
        isbn, reg_mark, reg_no, copy_symbol = row
        marc = fetch_book_data_from_aladin(isbn, reg_mark, reg_no, copy_symbol)
        tag_041, tag_546 = get_kormarc_041_tag(isbn)
        title, author, nlk_fields = generate_nlk_marc_fields(isbn)
        if marc:
            if tag_041: marc += f"\n={tag_041}"
            if tag_546: marc += f"\n=546  \\${tag_546}"
            if nlk_fields: marc += "\n" + "\n".join(nlk_fields)
            st.code(marc, language="text")
            marc_results.append(marc)

    full_text = "\n\n".join(marc_results)
    st.download_button("ğŸ“¦ ëª¨ë“  MARC ë‹¤ìš´ë¡œë“œ", data=full_text, file_name="marc_output.txt", mime="text/plain")

# ğŸ“„ ì˜ˆì‹œíŒŒì¼ ë‹¤ìš´ë¡œë“œ
example_csv = "ISBN,ë“±ë¡ê¸°í˜¸,ë“±ë¡ë²ˆí˜¸,ë³„ì¹˜ê¸°í˜¸\n'9791173473968,JUT,12345,TCH\n"
buffer = io.BytesIO()
buffer.write(example_csv.encode("utf-8-sig"))
buffer.seek(0)
st.markdown("""
ğŸ“Œ **ì„œì‹ íŒŒì¼ ì‚¬ìš© ì•ˆë‚´**  
ì„œì‹ íŒŒì¼ì˜ ë‘ ë²ˆì§¸ ì¤„ì€ ì˜ˆì‹œ ë°ì´í„°ì…ë‹ˆë‹¤. ISBN ì• ì‘ì€ë”°ì˜´í‘œ(`'`)ëŠ” Excelì—ì„œ ìˆ«ì ìë™ë³€í™˜ì„ ë§‰ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤. ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì‚­ì œí•´ ì£¼ì„¸ìš”.
""")
st.download_button("ğŸ“„ ì„œì‹ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=buffer, file_name="isbn_template.csv", mime="text/csv")

# ğŸ”— ì¶œì²˜ í‘œì‹œ
st.markdown("""
<div style='text-align: center; font-size: 14px; color: gray;'>
ğŸ“š <strong>ë„ì„œ DB ì œê³µ</strong> : <a href='https://www.aladin.co.kr' target='_blank'>ì•Œë¼ë”˜ ì¸í„°ë„·ì„œì (www.aladin.co.kr)</a>
</div>
""", unsafe_allow_html=True)
