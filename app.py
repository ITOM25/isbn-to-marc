import streamlit as st
import requests
import pandas as pd
import openai
import xml.etree.ElementTree as ET
import re
import io
from collections import Counter

# âœ… API í‚¤ (secrets.tomlì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°)
openai_key = st.secrets["api_keys"]["openai_key"]
aladin_key = st.secrets["api_keys"]["aladin_key"]
nlk_key = st.secrets["api_keys"]["nlk_key"]

# ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ (konlpy ì—†ì´)
def extract_keywords_from_text(text, top_n=7):
    words = re.findall(r'\b[\wê°€-í£]{2,}\b', text)
    filtered = [w for w in words if len(w) > 1]
    freq = Counter(filtered)
    return [kw for kw, _ in freq.most_common(top_n)]

# ğŸ“š ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_category_keywords(category_str):
    keywords = set()
    lines = category_str.strip().splitlines()
    for line in lines:
        parts = [x.strip() for x in line.split('>') if x.strip()]
        if parts:
            keywords.add(parts[-1])
    return list(keywords)

# ğŸ”§ GPT ê¸°ë°˜ KDC ì¶”ì²œ
def recommend_kdc(title, author, api_key):
    try:
        client = openai.OpenAI(api_key=api_key)
        prompt = f"""ë„ì„œ ì œëª©: {title}
ì €ì: {author}
ì´ ì±…ì˜ ì£¼ì œë¥¼ ê³ ë ¤í•˜ì—¬ í•œêµ­ì‹­ì§„ë¶„ë¥˜(KDC) ë²ˆí˜¸ í•˜ë‚˜ë¥¼ ì¶”ì²œí•´ ì£¼ì„¸ìš”.
ì •í™•í•œ ìˆ«ìë§Œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ê°„ë‹¨íˆ ì‘ë‹µí•´ ì£¼ì„¸ìš”:
KDC: 813.7"""
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
        )
        answer = response.choices[0].message.content
        for line in answer.strip().splitlines():
            if "KDC:" in line:
                return line.replace("KDC:", "").strip()
    except Exception as e:
        st.warning(f"ğŸ§  GPT ì˜¤ë¥˜: {e}")
    return "000"

# ğŸ“¡ ë¶€ê°€ê¸°í˜¸ ì¶”ì¶œ (êµ­ë¦½ì¤‘ì•™ë„ì„œê´€)
def fetch_additional_code_from_nlk(isbn):
    try:
        url = f"https://www.nl.go.kr/seoji/SearchApi.do?cert_key={nlk_key}&result_style=xml&page_no=1&page_size=10&isbn={isbn}"
        res = requests.get(url, timeout=10)
        res.raise_for_status()
        res.encoding = 'utf-8'
        root = ET.fromstring(res.text)
        doc = root.find('.//docs/e')
        if doc is not None:
            add_code = doc.findtext('EA_ADD_CODE')
            return add_code.strip() if add_code else ""
    except Exception as e:
        st.warning(f"ğŸ“¡ êµ­ì¤‘API ì˜¤ë¥˜: {e}")
    return ""

# ğŸ“„ 653 í•„ë“œ í‚¤ì›Œë“œ ìƒì„±
def generate_653_keywords(title, description, toc, category):
    keywords = set()
    keywords.update(extract_category_keywords(category))
    keywords.update(extract_keywords_from_text(title, 2))
    keywords.update(extract_keywords_from_text(description, 7))
    keywords.update(extract_keywords_from_text(toc, 7))
    return list(keywords)[:8]

# ğŸ“š MARC ìƒì„± (ì•Œë¼ë”˜ + GPT + êµ­ì¤‘)
@st.cache_data(show_spinner=False)
def fetch_book_data_from_aladin(isbn, reg_mark="", reg_no="", copy_symbol=""):
    try:
        url = f"https://www.aladin.co.kr/ttb/api/ItemLookUp.aspx?ttbkey={aladin_key}&itemIdType=ISBN&ItemId={isbn}&output=js&Version=20131101&optResult=ebookList,reviewList"
        response = requests.get(url, verify=False, timeout=10)
        response.raise_for_status()
        data = response.json().get("item", [{}])[0]
    except Exception as e:
        st.error(f"ğŸš¨ ì•Œë¼ë”˜ API ì˜¤ë¥˜: {e}")
        return ""

    title = data.get("title", "ì œëª©ì—†ìŒ")
    author = data.get("author", "ì €ìë¯¸ìƒ")
    publisher = data.get("publisher", "ì¶œíŒì‚¬ë¯¸ìƒ")
    pubdate = data.get("pubDate", "2025")[:4]
    price = data.get("priceStandard")
    series_title = data.get("seriesInfo", {}).get("seriesName", "").strip()
    category = data.get("categoryName", "")
    description = data.get("description", "")
    toc = data.get("subInfo", {}).get("toc", "")

    add_code = fetch_additional_code_from_nlk(isbn)
    kdc = recommend_kdc(title, author, api_key=openai_key)
    keywords = generate_653_keywords(title, description, toc, category)

    marc = f"=007  ta\n=245  00$a{title} /$c{author}\n=260  \\$aì„œìš¸ :$b{publisher},$c{pubdate}.\n=020  \\$a{isbn}"
    if add_code:
        marc += f"$g{add_code}"
    if price:
        marc += f":$c\\{price}"
    if kdc and kdc != "000":
        marc += f"\n=056  \\$a{kdc}$26"
    if keywords:
        marc += "\n=653  \\" + "".join([f"$a{kw}" for kw in keywords])
    if series_title:
        marc += f"\n=490  10$a{series_title} ;$v\n=830  \\0$a{series_title} ;$v"
    if price:
        marc += f"\n=950  0\\$b\\{price}"
    if reg_mark or reg_no or copy_symbol:
        marc += f"\n=049  0\\$I{reg_mark}{reg_no}"
        if copy_symbol:
            marc += f"$f{copy_symbol}"

    return marc

# ğŸ›ï¸ Streamlit UI
st.title("ğŸ“š ISBN to MARC ë³€í™˜ê¸° (Cloudìš©, konlpy ì—†ì´)")

isbn_list = []
single_isbn = st.text_input("ğŸ”¹ ë‹¨ì¼ ISBN ì…ë ¥", placeholder="ì˜ˆ: 9788936434267")
if single_isbn.strip():
    isbn_list = [[single_isbn.strip(), "", "", ""]]

uploaded_file = st.file_uploader("ğŸ“ CSV ì—…ë¡œë“œ (ISBN, ë“±ë¡ê¸°í˜¸, ë“±ë¡ë²ˆí˜¸, ë³„ì¹˜ê¸°í˜¸)", type="csv")
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    if {'ISBN', 'ë“±ë¡ê¸°í˜¸', 'ë“±ë¡ë²ˆí˜¸', 'ë³„ì¹˜ê¸°í˜¸'}.issubset(df.columns):
        isbn_list = df[['ISBN', 'ë“±ë¡ê¸°í˜¸', 'ë“±ë¡ë²ˆí˜¸', 'ë³„ì¹˜ê¸°í˜¸']].dropna(subset=['ISBN']).values.tolist()
    else:
        st.error("âŒ í•„ìš”í•œ ì—´ì´ ì—†ìŠµë‹ˆë‹¤: ISBN, ë“±ë¡ê¸°í˜¸, ë“±ë¡ë²ˆí˜¸, ë³„ì¹˜ê¸°í˜¸")

if isbn_list:
    st.subheader("ğŸ“„ MARC ì¶œë ¥")
    marc_results = []
    for row in isbn_list:
        isbn, reg_mark, reg_no, copy_symbol = row
        marc = fetch_book_data_from_aladin(isbn, reg_mark, reg_no, copy_symbol)
        if marc:
            st.code(marc, language="text")
            marc_results.append(marc)

    full_text = "\n\n".join(marc_results)
    st.download_button("ğŸ“¦ ëª¨ë“  MARC ë‹¤ìš´ë¡œë“œ", data=full_text, file_name="marc_output.txt", mime="text/plain")

# ğŸ“„ í…œí”Œë¦¿ ì˜ˆì‹œ ë‹¤ìš´ë¡œë“œ
example_csv = "ISBN,ë“±ë¡ê¸°í˜¸,ë“±ë¡ë²ˆí˜¸,ë³„ì¹˜ê¸°í˜¸\n9791173473968,JUT,12345,TCH\n"
buffer = io.BytesIO()
buffer.write(example_csv.encode("utf-8-sig"))
buffer.seek(0)
st.download_button("ğŸ“„ ì„œì‹ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=buffer, file_name="isbn_template.csv", mime="text/csv")

# â¬‡ï¸ í•˜ë‹¨ ë§ˆí¬
st.markdown("""
<div style='text-align: center; font-size: 14px; color: gray;'>
ğŸ“š <strong>ë„ì„œ DB ì œê³µ</strong> : <a href='https://www.aladin.co.kr' target='_blank'>ì•Œë¼ë”˜ ì¸í„°ë„·ì„œì (www.aladin.co.kr)</a>
</div>
""", unsafe_allow_html=True)
