import streamlit as st
import requests
import pandas as pd
import openai
import xml.etree.ElementTree as ET
import re
import io

# âœ… API í‚¤ë“¤ (secrets.tomlì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°)
openai_key = st.secrets["api_keys"]["openai_key"]
aladin_key = st.secrets["api_keys"]["aladin_key"]
nlk_key = st.secrets["api_keys"]["nlk_key"]

# âœ… GPT ê¸°ë°˜ KDC ì¶”ì²œ (openai>=1.0 ë°©ì‹)
@st.cache_data(show_spinner=False)
def recommend_kdc(title, author, api_key):
    try:
        client = openai.OpenAI(api_key=api_key)

        prompt = f"""ë„ì„œ ì œëª©: {title}
ì €ì: {author}
ì´ ì±…ì˜ ì£¼ì œë¥¼ ê³ ë ¤í•˜ì—¬ í•œêµ­ì‹­ì§„ë¶„ë¥˜(KDC) ë²ˆí˜¸ í•˜ë‚˜ë¥¼ ì¶”ì²œí•´ ì£¼ì„¸ìš”.
ì •í™•í•œ ìˆ«ìë§Œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ê°„ë‹¨íˆ ì‘ë‹µí•´ ì£¼ì„¸ìš”:
KDC: 813.7"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
        )

        answer = response.choices[0].message.content
        for line in answer.strip().splitlines():
            if "KDC:" in line:
                return line.replace("KDC:", "").strip()

    except Exception as e:
        st.warning(f"GPT ì˜¤ë¥˜: {e}")
    return "000"

# ğŸ“š NLK ê¸°ë°˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def fetch_from_nlk(isbn, nlk_key):
    url = f"https://www.nl.go.kr/seoji/SearchApi.do?cert_key={nlk_key}&result_style=xml&page_no=1&page_size=10&isbn={isbn}"
    try:
        res = requests.get(url, timeout=10)
        res.encoding = 'utf-8'
        root = ET.fromstring(res.text)
        doc = root.find('.//docs/e')
        title = doc.findtext('TITLE')
        author = doc.findtext('AUTHOR')
        return title, author
    except:
        return "ì œëª©ì—†ìŒ", "ì§€ì€ì´ ë¯¸ìƒ"

# ğŸ“š ë¶€ê°€ê¸°í˜¸ ADDCODE ì¶”ì¶œ í•¨ìˆ˜
def fetch_additional_code_from_nlk(isbn):
    try:
        url = f"https://www.nl.go.kr/seoji/SearchApi.do?cert_key={nlk_key}&result_style=xml&page_no=1&page_size=10&isbn={isbn}"
        res = requests.get(url, timeout=10)
        res.encoding = 'utf-8'
        root = ET.fromstring(res.text)

        doc = root.find('.//docs/e')  # í•µì‹¬! ì—¬ê¸°ê°€ ì˜ëª»ëë˜ ë¶€ë¶„
        if doc is not None:
            add_code = doc.findtext('EA_ADD_CODE')
            return add_code.strip() if add_code else ""
    except Exception as e:
        print(f"ğŸ“¡ ë¶€ê°€ê¸°í˜¸ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
    return ""



# ğŸ“š ì•Œë¼ë”˜ ê¸°ë°˜ MARC ìƒì„±
@st.cache_data(show_spinner=False)
def fetch_book_data_from_aladin(isbn, reg_mark="", reg_no="", copy_symbol=""):
    url = f"https://www.aladin.co.kr/ttb/api/ItemLookUp.aspx?ttbkey={aladin_key}&itemIdType=ISBN&ItemId={isbn}&output=js&Version=20131101"
    response = requests.get(url, verify=False)
    data = response.json().get("item", [{}])[0]

    title = data.get("title", "ì œëª©ì—†ìŒ")
    author = data.get("author", "ì €ìë¯¸ìƒ")
    publisher = data.get("publisher", "ì¶œíŒì‚¬ë¯¸ìƒ")
    pubdate = data.get("pubDate", "2025")[:4]
    price = data.get("priceStandard")
    series_title = data.get("seriesInfo", {}).get("seriesName", "").strip()

    # ë¶€ê°€ê¸°í˜¸ ê°€ì ¸ì˜¤ê¸°
    add_code = fetch_additional_code_from_nlk(isbn)

    # GPT ê¸°ë°˜ KDC ì¶”ì²œ
    kdc = recommend_kdc(title, author, api_key=openai_key)

    # ğŸ“Œ MARC í•„ë“œ ì‘ì„±
    marc = f"=007  ta\n=001  {isbn}\n=245  10$a{title} /$c{author}\n=260  \\$aì„œìš¸ :$b{publisher},$c{pubdate}.\n=020  \\$a{isbn}"
    if add_code:
        marc += f"$g{add_code}"
    if price:
        marc += f":$c\\{price}"
    if kdc and kdc != "000":
        marc += f"\n=056  \\$a{kdc}$26"
    if series_title:
        marc += f"\n=490  10$a{series_title} ;$v\n=830  \\0$a{series_title} ;$v"
    if price:
        marc += f"\n=950  0\\$b\\{price}"
    if reg_mark or reg_no or copy_symbol:
        marc += f"\n=049  0\\$I{reg_mark}{reg_no}"
        if copy_symbol:
            marc += f"$f{copy_symbol}"

    return marc




# ğŸ›ï¸ UI ì˜ì—­
st.title("ğŸ“š ISBN to MARC ë³€í™˜ê¸° (GPT ê¸°ë°˜ KDC ì¶”ì²œ)")

isbn_list = []
single_isbn = st.text_input("ğŸ”¹ ë‹¨ì¼ ISBN ì…ë ¥", placeholder="ì˜ˆ: 9788936434267")

if single_isbn.strip():
    isbn_list = [[single_isbn.strip(), "", "", ""]]

uploaded_file = st.file_uploader("ğŸ“ CSV ì—…ë¡œë“œ (ISBN, ë“±ë¡ê¸°í˜¸, ë“±ë¡ë²ˆí˜¸, ë³„ì¹˜ê¸°í˜¸)", type="csv")
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    if {'ISBN', 'ë“±ë¡ê¸°í˜¸', 'ë“±ë¡ë²ˆí˜¸', 'ë³„ì¹˜ê¸°í˜¸'}.issubset(df.columns):
        isbn_list = df[['ISBN', 'ë“±ë¡ê¸°í˜¸', 'ë“±ë¡ë²ˆí˜¸', 'ë³„ì¹˜ê¸°í˜¸']].dropna(subset=['ISBN']).values.tolist()
    else:
        st.error("âŒ í•„ìš”í•œ ì—´ì´ ì—†ìŠµë‹ˆë‹¤: ISBN, ë“±ë¡ê¸°í˜¸, ë“±ë¡ë²ˆí˜¸, ë³„ì¹˜ê¸°í˜¸")

if isbn_list:
    st.subheader("ğŸ“„ MARC ì¶œë ¥")
    marc_results = []
    for row in isbn_list:
        isbn, reg_mark, reg_no, copy_symbol = row
        marc = fetch_book_data_from_aladin(isbn, reg_mark, reg_no, copy_symbol)
        if marc:
            marc = f"=007  ta\n" + marc
            st.code(marc, language="text")
            marc_results.append(marc)

    full_text = "\n\n".join(marc_results)
    st.download_button("ğŸ“¦ ëª¨ë“  MARC ë‹¤ìš´ë¡œë“œ", data=full_text, file_name="marc_output.txt", mime="text/plain")

# ğŸ“„ ì˜ˆì‹œíŒŒì¼ ë‹¤ìš´ë¡œë“œ
example_csv = "ISBN,ë“±ë¡ê¸°í˜¸,ë“±ë¡ë²ˆí˜¸,ë³„ì¹˜ê¸°í˜¸\n'9791173473968,JUT,12345,TCH\n"
buffer = io.BytesIO()
buffer.write(example_csv.encode("utf-8-sig"))
buffer.seek(0)
st.download_button("ğŸ“„ ì„œì‹ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=buffer, file_name="isbn_template.csv", mime="text/csv")

# ğŸ”— ì¶œì²˜ í‘œì‹œ
st.markdown("""
<div style='text-align: center; font-size: 14px; color: gray;'>
ğŸ“š <strong>ë„ì„œ DB ì œê³µ</strong> : <a href='https://www.aladin.co.kr' target='_blank'>ì•Œë¼ë”˜ ì¸í„°ë„·ì„œì (www.aladin.co.kr)</a>
</div>
""", unsafe_allow_html=True)
